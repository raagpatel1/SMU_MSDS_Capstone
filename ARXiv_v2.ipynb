{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sourcing Data ARXiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_stat.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "search_query = 'cat:stat*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Statistics'\n",
    "cat_code = 'stat'\n",
    "subject = 'Statistics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url, timeout=10)  # Set a timeout value (e.g., 10 seconds)\n",
    "        data = response.read().decode('utf-8')\n",
    "        response.close()\n",
    "        return data\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "        \n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "\n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "\n",
    "    if data is None:\n",
    "        # If there was an error or no data, you can handle it here (e.g., retry or skip)\n",
    "        print(\"Skipping this request.\")\n",
    "        return\n",
    "\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_stat = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_stat = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_stat['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_stat[f'Author_{i+1}'] = df_stat['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_stat.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_stat.csv'\n",
    "    df_stat.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_stat  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_stat = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astrophysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
      "C:\\Users\\rosjo\\AppData\\Local\\Temp\\ipykernel_19016\\2129506389.py:78: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_astroph.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "search_query = 'cat:astro-ph*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Astrophysics'\n",
    "cat_code = 'astro-ph'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url, timeout=10)  # Set a timeout value (e.g., 10 seconds)\n",
    "        data = response.read().decode('utf-8')\n",
    "        response.close()\n",
    "        return data\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "\n",
    "    if data is None:\n",
    "        # If there was an error or no data, you can handle it here (e.g., retry or skip)\n",
    "        print(\"Skipping this request.\")\n",
    "        return\n",
    "\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_astroph = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_astroph= pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_astroph['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_astroph[f'Author_{i+1}'] = df_astroph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_astroph.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_astroph.csv'\n",
    "    df_astroph.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_astroph  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_astroph = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condensed Matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_condmat.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "search_query = 'cat:cond-mat*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Condensed Matter'\n",
    "cat_code = 'cond-mat'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url, timeout=10)  # Set a timeout value (e.g., 10 seconds)\n",
    "        data = response.read().decode('utf-8')\n",
    "        response.close()\n",
    "        return data\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "\n",
    "    if data is None:\n",
    "        # If there was an error or no data, you can handle it here (e.g., retry or skip)\n",
    "        print(\"Skipping this request.\")\n",
    "        return\n",
    "\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_condmat = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_condmat = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_condmat['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_condmat[f'Author_{i+1}'] = df_condmat['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_condmat.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_condmat.csv'\n",
    "    df_condmat.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_condmat  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_condmat = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Relativity and Quantum Cosmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_grqc.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:gr-qc*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'General Relativity and Quantum Cosmology'\n",
    "cat_code = 'gr-qc'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_grqc = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_grqc = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_grqc['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_grqc[f'Author_{i+1}'] = df_grqc['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_grqc.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_grqc.csv'\n",
    "    df_grqc.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_grqc  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_grqc = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Energy Physics - Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_hepex.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:hep-ex*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'High Energy Physics - Experiment'\n",
    "cat_code = 'hep-ex'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "        \n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "\n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_hepex = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_hepex = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_hepex['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_hepex[f'Author_{i+1}'] = df_hepex['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_hepex.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_hepex.csv'\n",
    "    df_hepex.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_hepex  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_hepex = main()  # Get the DataFrame from the main function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Energy Physics - Lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_heplat.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:hep-lat*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'High Energy Physics - Lattice'\n",
    "cat_code = 'hep-lat'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "        \n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_heplat = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_heplat = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_heplat['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_heplat[f'Author_{i+1}'] = df_heplat['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_heplat.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_heplat.csv'\n",
    "    df_heplat.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_heplat  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_heplat = main()  # Get the DataFrame from the main function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Energy Physics - Phenomenology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_hepph.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:hep-ph*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'High Energy Physics - Phenomenology'\n",
    "cat_code = 'hep-ph'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_hepph = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_hepph = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_hepph['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_hepph[f'Author_{i+1}'] = df_hepph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_hepph.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_hepph.csv'\n",
    "    df_hepph.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_hepph  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_hepph = main()  # Get the DataFrame from the main function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Energy Physics - Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_hepth.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:hep-th*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'High Energy Physics - Theory'\n",
    "cat_code = 'hep-th'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_hepth = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_hepth = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_hepth['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_hepth[f'Author_{i+1}'] = df_hepth['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_hepth.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_hepth.csv'\n",
    "    df_hepth.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_hepth  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_hepth = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematical Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_mathph.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:math-ph*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Mathematical Physics'\n",
    "cat_code = 'math-ph'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_mathph = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_mathph = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_mathph['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_mathph[f'Author_{i+1}'] = df_mathph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_mathph.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_mathph.csv'\n",
    "    df_mathph.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_mathph  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_mathph = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nonlinear Sciences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_nlin.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:nlin*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Nonlinear Sciences'\n",
    "cat_code = 'nlin'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_nlin = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_nlin = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_nlin['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_nlin[f'Author_{i+1}'] = df_nlin['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_nlin.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_nlin.csv'\n",
    "    df_nlin.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_nlin  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_nlin = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuclear Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_nuclex.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:nucl-ex*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Nuclear Experiment'\n",
    "cat_code = 'nucl-ex'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_nuclex = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_nuclex = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_nuclex['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_nuclex[f'Author_{i+1}'] = df_nuclex['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_nuclex.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_nuclex.csv'\n",
    "    df_nuclex.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_nuclex  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_nuclex = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuclear Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_nuclth.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:nucl-th*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Nuclear Theory'\n",
    "cat_code = 'nucl-th'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_nuclth = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_nuclth = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_nuclth['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_nuclth[f'Author_{i+1}'] = df_nuclth['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_nuclth.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_nuclth.csv'\n",
    "    df_nuclth.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_nuclth  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_nuclth = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_physics.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:physics*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Physics'\n",
    "cat_code = 'physics'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_physics = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_physics = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_physics['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_physics[f'Author_{i+1}'] = df_physics['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_physics.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_physics.csv'\n",
    "    df_physics.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_physics  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_physics = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum Physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_quantph.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:quant-ph*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Quantum Physics'\n",
    "cat_code = 'quant-ph'\n",
    "subject = 'Physics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_quantph = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_quantph = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_quantph['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_quantph[f'Author_{i+1}'] = df_quantph['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_quantph.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_quantph.csv'\n",
    "    df_quantph.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_quantph  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_quantph = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_math.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:math*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Mathematics'\n",
    "cat_code = 'math'\n",
    "subject = 'Mathematics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_math = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_math = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_math['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_math[f'Author_{i+1}'] = df_math['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_math.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_math.csv'\n",
    "    df_math.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_math  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_math = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Research Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_CoRR.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:CoRR*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Computing Research Repository'\n",
    "cat_code = 'CoRR'\n",
    "subject = 'Computer Science'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "            \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_CoRR = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_CoRR = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_CoRR['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_CoRR[f'Author_{i+1}'] = df_CoRR['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_CoRR.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_CoRR.csv'\n",
    "    df_CoRR.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_CoRR  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_CoRR = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantitative Biology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_qbio.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:q-bio*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Quantitative Biology'\n",
    "cat_code = 'q-bio'\n",
    "subject = 'Quantitative Biology'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_qbio = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_qbio = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_qbio['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_qbio[f'Author_{i+1}'] = df_qbio['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_qbio.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_qbio.csv'\n",
    "    df_qbio.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_qbio  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_qbio = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantitative Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_qfin.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:q-fin*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Quantitative Finance'\n",
    "cat_code = 'q-fin'\n",
    "subject = 'Quantitative Finance'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_qfin = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_qfin = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_qfin['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_qfin[f'Author_{i+1}'] = df_qfin['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_qfin.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_qfin.csv'\n",
    "    df_qfin.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_qfin  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_qfin = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electrical Engineering and Systems Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_eess.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:eess*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Electrical Engineering and Systems Science'\n",
    "cat_code = 'eess'\n",
    "subject = 'Electrical Engineering and Systems Science'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_eess = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_eess = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_eess['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_eess[f'Author_{i+1}'] = df_eess['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_eess.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_eess.csv'\n",
    "    df_eess.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_eess  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_eess = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Economics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to arxiv_data_econ.csv\n"
     ]
    }
   ],
   "source": [
    "search_query = 'cat:econ*'\n",
    "start_index = 0\n",
    "max_results = 1000  # Set the desired number of results\n",
    "\n",
    "# Add the desired values for Category, Cat_code, and Subject\n",
    "category = 'Economics'\n",
    "cat_code = 'econ'\n",
    "subject = 'Economics'\n",
    "\n",
    "def make_request_with_delay(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    data = response.read().decode('utf-8')\n",
    "    response.close()\n",
    "    return data\n",
    "\n",
    "def parse_response(response):\n",
    "    root = ET.fromstring(response)\n",
    "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
    "    \n",
    "    results = []\n",
    "    for entry in entries:\n",
    "        authors = entry.findall('{http://www.w3.org/2005/Atom}author/{http://www.w3.org/2005/Atom}name')\n",
    "        author_names = [author.text for author in authors]\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        published_date = entry.find('{http://www.w3.org/2005/Atom}published').text\n",
    "        updated_date = entry.find('{http://www.w3.org/2005/Atom}updated').text\n",
    "        year = published_date[:4]\n",
    "\n",
    "        # Extract the DOI if available\n",
    "        doi_element = entry.find('{http://arxiv.org/schemas/atom}doi')\n",
    "        doi = doi_element.text if doi_element is not None else None\n",
    "        \n",
    "        if '2018' <= year <= '2023':\n",
    "            results.append({\n",
    "                'DOI': doi,  # Include the DOI\n",
    "                'Category': category,\n",
    "                'Cat_code': cat_code,\n",
    "                'Subject': subject,\n",
    "                'Authors': author_names,\n",
    "                'Title': title,\n",
    "                'Published Date': published_date,\n",
    "                'Updated Date': updated_date,\n",
    "                'Year': year\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start={start_index}&max_results={max_results}'\n",
    "    data = make_request_with_delay(url)\n",
    "    parsed_data = parse_response(data)\n",
    "\n",
    "    if not parsed_data:\n",
    "        # If no data, create an empty DataFrame with desired columns\n",
    "        df_econ = pd.DataFrame(columns=['Category', 'Cat_code', 'Subject', 'Authors', 'Title', 'Published Date', 'Updated Date', 'Year'])\n",
    "    else:\n",
    "        # Create DataFrame\n",
    "        df_econ = pd.DataFrame(parsed_data)\n",
    "\n",
    "        # Split authors into separate columns\n",
    "        max_authors = max(len(authors) for authors in df_econ['Authors'])\n",
    "        for i in range(max_authors):\n",
    "            df_econ[f'Author_{i+1}'] = df_econ['Authors'].apply(lambda x: x[i] if len(x) > i else None)\n",
    "\n",
    "        # Drop the original 'Authors' column\n",
    "        df_econ.drop('Authors', axis=1, inplace=True)\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_filename = 'arxiv_data_econ.csv'\n",
    "    df_econ.to_csv(csv_filename, index=False)\n",
    "    print(f'Data saved to {csv_filename}')\n",
    "\n",
    "    # Introduce a delay of 3 seconds before making the next request\n",
    "    time.sleep(3)\n",
    "\n",
    "    return df_econ  # Return the DataFrame\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_econ = main()  # Get the DataFrame from the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidated DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              DOI      Category  Cat_code    Subject  \\\n",
      "0                            None  Astrophysics  astro-ph    Physics   \n",
      "1                            None  Astrophysics  astro-ph    Physics   \n",
      "2                            None  Astrophysics  astro-ph    Physics   \n",
      "3     10.1051/0004-6361/202243511  Astrophysics  astro-ph    Physics   \n",
      "4     10.1051/0004-6361/202244242  Astrophysics  astro-ph    Physics   \n",
      "...                           ...           ...       ...        ...   \n",
      "5399                         None     Economics      econ  Economics   \n",
      "5400                         None     Economics      econ  Economics   \n",
      "5401               10.1086/718983     Economics      econ  Economics   \n",
      "5402   10.1007/s00199-023-01485-1     Economics      econ  Economics   \n",
      "5403                         None     Economics      econ  Economics   \n",
      "\n",
      "                                                  Title        Published Date  \\\n",
      "0     (Un)conscious Bias in the Astronomical Profess...  2019-07-10T03:25:44Z   \n",
      "1     VLBI20-30: a scientific roadmap for the next d...  2020-07-05T14:11:03Z   \n",
      "2                     Well-being in French Astrophysics  2022-02-03T18:47:19Z   \n",
      "3     Gaia Data Release 3: Chemical cartography of t...  2022-06-11T13:55:08Z   \n",
      "4     Gaia Data Release 3. Summary of the variabilit...  2022-06-13T18:51:34Z   \n",
      "...                                                 ...                   ...   \n",
      "5399      An algebraic approach to revealed preferences  2021-05-31T17:34:06Z   \n",
      "5400                         Optimal Taxation of Assets  2021-06-05T10:27:19Z   \n",
      "5401  Decentralizing Centralized Matching Markets: I...  2021-07-04T03:37:19Z   \n",
      "5402  Mobility decisions, economic dynamics and epid...  2021-07-04T22:54:40Z   \n",
      "5403   Centralized Matching with Incomplete Information  2021-07-08T20:32:22Z   \n",
      "\n",
      "              Updated Date  Year                 Author_1  \\\n",
      "0     2019-07-10T03:25:44Z  2019        Alessandra Aloisi   \n",
      "1     2020-07-05T14:11:03Z  2020          Tiziana Venturi   \n",
      "2     2022-02-03T18:47:19Z  2022               N. A. Webb   \n",
      "3     2022-06-11T13:55:08Z  2022       Gaia Collaboration   \n",
      "4     2022-06-13T18:51:34Z  2022                  L. Eyer   \n",
      "...                    ...   ...                      ...   \n",
      "5399  2021-05-31T17:34:06Z  2021            Mikhail Freer   \n",
      "5400  2021-06-05T10:27:19Z  2021         Nicolaus Tideman   \n",
      "5401  2022-06-04T20:54:41Z  2021            Julien Grenet   \n",
      "5402  2021-07-04T22:54:40Z  2021           Giorgio Fabbri   \n",
      "5403  2021-07-08T20:32:22Z  2021  Marcelo Ariel Fernandez   \n",
      "\n",
      "                  Author_2  ... Author_442 Author_443      Author_444  \\\n",
      "0               Neill Reid  ...       None       None            None   \n",
      "1             Zsolt Paragi  ...       None       None            None   \n",
      "2                   C. Bot  ...       None       None            None   \n",
      "3          A. Recio-Blanco  ...  M. Weiler  T. Wevers  Ł. Wyrzykowski   \n",
      "4                M. Audard  ...       None       None            None   \n",
      "...                    ...  ...        ...        ...             ...   \n",
      "5399      Cesar Martinelli  ...        NaN        NaN             NaN   \n",
      "5400  Thomas Mecherikunnel  ...        NaN        NaN             NaN   \n",
      "5401            YingHua He  ...        NaN        NaN             NaN   \n",
      "5402    Salvatore Federico  ...        NaN        NaN             NaN   \n",
      "5403          Kirill Rudov  ...        NaN        NaN             NaN   \n",
      "\n",
      "     Author_445 Author_446 Author_447 Author_448 Author_449  Author_450  \\\n",
      "0          None       None       None       None       None        None   \n",
      "1          None       None       None       None       None        None   \n",
      "2          None       None       None       None       None        None   \n",
      "3     A. Yoldas   P. Yvard    H. Zhao   J. Zorec  S. Zucker  T. Zwitter   \n",
      "4          None       None       None       None       None        None   \n",
      "...         ...        ...        ...        ...        ...         ...   \n",
      "5399        NaN        NaN        NaN        NaN        NaN         NaN   \n",
      "5400        NaN        NaN        NaN        NaN        NaN         NaN   \n",
      "5401        NaN        NaN        NaN        NaN        NaN         NaN   \n",
      "5402        NaN        NaN        NaN        NaN        NaN         NaN   \n",
      "5403        NaN        NaN        NaN        NaN        NaN         NaN   \n",
      "\n",
      "     Authors  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n",
      "...      ...  \n",
      "5399     NaN  \n",
      "5400     NaN  \n",
      "5401     NaN  \n",
      "5402     NaN  \n",
      "5403     NaN  \n",
      "\n",
      "[5404 rows x 459 columns]\n",
      "Data saved to arxiv_data_consol.csv\n"
     ]
    }
   ],
   "source": [
    "consolidated_df = pd.concat([df_astroph, df_condmat, df_grqc, df_hepex, df_heplat, df_hepph, df_hepth, df_mathph, df_nlin, df_nuclex, \n",
    "                             df_nuclth, df_physics, df_quantph, df_math, df_CoRR, df_qbio, df_qfin, df_stat, df_eess, df_econ], axis=0, join='outer', ignore_index=True)\n",
    "\n",
    "# Display the consolidated DataFrame\n",
    "print(consolidated_df)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "csv_filename = 'arxiv_data_consol.csv'\n",
    "consolidated_df.to_csv(csv_filename, index=False)\n",
    "print(f'Data saved to {csv_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5404 entries, 0 to 5403\n",
      "Columns: 459 entries, DOI to Authors\n",
      "dtypes: object(459)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "consolidated_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstoneb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
